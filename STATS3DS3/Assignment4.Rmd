---
title: |
  | STATS 3DS3
  | Homework assignment 4
author: 
  - "Ling Lu(400193735)"
date: "03/01/2021"
output: 
  pdf_document:
    includes:
      in_header: header.tex
bibliography: STATS3DS3.bib

---

**Submit to Crowdmark using the link that was emailed to you.**

**Due before 10:00 PM on Wednesday, March 10th, 2021.**

**Assignments submitted after the due date will receive a zero grade.**

**Answer all the questions.** 

**Grading scheme: $\left\lbrace 0, 1, 2\right\rbrace$ points per question, including reference section, total of 34. We will convert this to 100\%.** 

**Your assignment must conform to the Assignment Standards listed below.**

* Write your name and student number on the title page. Submit the title page for Q0. There is no grade for Q0. We will not grade assignments without Q0. 

* You may discuss homework problems with other students, but you have to prepare the written assignments yourself. You can mention one helper's name in the helper's section only. 

* Please combine all your answers, the computer code, and the figures into one PDF file, and submit a copy to Crowdmark.

* Please use **newpage** to write a solution for each part of a question.

* Please choose the pages for each part of a question in Crowdmark. 

* No screenshots are accepted for any reason.

* The writing and referencing should be appropriate to the undergraduate level.

* Various tools, including publicly available internet tools, may be used by the instructor to check the originality of submitted work.



\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      collapse = TRUE, 
                      comment = "#>")
```

\newpage

## Question 1

1.1 If we consider a supervised classification problem, what is the limitation of the K-nearest neighbor method?

There are few disadvantages of KNN. 
1. KNN does not work well with large dataset. 
2.It does not work well with high dimension since it is hard for the algorithm to calculate the distance in each dimension. 
3. we need to do feature scaling before applying KNN or it may generate wrong predictions. 
4.KNN is sensitive to missing values and outliers.


\newpage 
1.2 If we consider a supervised classification problem, what is the disadvantage of the decision trees method?

1.decision tree model is sensitive since a small change in the data will generate a large change in the tree sturcture.
2.the space and time complexity of decision tree model is relatively higher.
3.it takes longer training time as the complexity is high.


\newpage 

1.3 How can we improve the prediction accuracy in decision trees?

we can improve the prediction accuracy in decision trees using Bootstraping.

\newpage
## Question 2

This question is from **ISLR** Exercises 5.4.

We will consider the _Boston_ housing data set, from the MASS library.

2.1 Based on this data set, provide an estimate for the population mean of _medv_. Call this estimate $\hat{\mu}$.
```{r}
library(MASS)
attach(Boston)
mu.hat <-mean(medv)
mu.hat
```

\newpage
2.2 Provide an estimate of the standard error of $\hat{\mu}$. Interpret this result.

[Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations.]
```{r}
se <- sqrt(var(Boston$medv)/nrow(Boston))
se
```
Standard error is an indication of reliability of the mean, in this case, the value of standard error is 0.4088611 which is relatively small so we can say that the sample mean is an accurate reflection of the actual population mean.
\newpage

2.3 Now estimate the standard error of $\hat{\mu}$ using the bootstrap. How does this compare to your answer from (2.2)?



```{r}
library(tidyverse)
library(boot)
set.seed(1)
boot.fn <- function(data, index) {
    mu <- mean(data[index])
    return (mu)
}
boot(medv, boot.fn, 1000)
```
the bootstrap estimated standard error of $\hat{\mu}$ of 0.4106622 is close to the estimate found in (b) of 0.4088611

\newpage
2.4 Based on this data set, provide an estimate, $\hat{\mu}_{\text{median}}$ for the median value of _medv_ in the population.
```{r}
med.hat <- median(medv)
med.hat
```


\newpage
2.5 We now would like to estimate the standard error of $\hat{\mu}_{\text{median}}$. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.
```{r}
boot.fn <- function(data, index) {
    mu <- median(data[index])
    return (mu)
}
boot(medv, boot.fn, 1000)
```
the estimated median value is 21.2 which is the same as the value we got in 2.4.  The standard error is 0.3770241 is relatively small compared to median value.

\newpage

# Question 3
Consider a dataset that you wish to apply a model to, with the goal of measuring the prediction accuracy of your model (e.g., a classification problem).

3.1 Give one advantage of using cross-validation in this context.

Cross-validation would will give us the benefit of predictive performance and accuracy of out of sample accuracy in structured way.

\newpage
3.2 Give a brief description of how a dataset is partitioned when carrying out cross-validation.

the data will be divided into subset(test set and training set) as per overfitting problem of sample in new dataset. 

\newpage

3.3 What does the "K" in K-fold cross-validation stand for? (i.e., explain its significance)

it stands for the numbers of group that is created by partitioning of dataset.
\newpage

## Questions 4

Consider the _Hitters_ dataset from the ISLR package in R.

You will be predicting log-salary using different methods, but first you must prepare the dataset. See the R code that was posted for Lab 7. This will show you, for the _Hitters_ dataset, how to remove missing data, and also how to remove the Salary variable, and replace it with logSalary. You should have a total of 19 predictor variables, as well as the logSalary variable. Set the seed to 1.


4.1 Partition your data into a 75\% training set and a 25\% test set (hold-out set). 

```{r }
library(tidyverse)
library(randomForest)
data(Hitters, package="ISLR")
head(Hitters)
names(Hitters)

Hitters <- Hitters %>% 
  filter(complete.cases(.))

Hitters <- Hitters %>% 
  mutate(Hitters, 
         logSalary = log(Hitters$Salary)) %>%
  select(-Salary)

set.seed(1)
train <- sample (
  1: nrow(Hitters), 
  nrow(Hitters)/1.3333)

hitters_test <- Hitters %>% 
  slice(-train) %>% 
  pull(logSalary)
```

\newpage

4.2 Apply Bagging to the training set and then predict logSalary for the test set. Report the mean squared error (MSE) for the test set result.

```{r}
library(ipred)
set.seed(1)
bag_train <- bagging(
  logSalary~.,
  data=Hitters,
  subset=train)

test_pre <- predict(bag_train,newdata= Hitters[-train,])
round(mean((test_pre-hitters_test)^2),digits=2)
```
the MSE is 0.29

\newpage

4.3 Apply Random Forests to the training set and then predict logSalary for the test set. Use three sensible values of $m$ (number of predictor variables available to split on) and report all three results (MSE), stating which one is the best.
```{r}
library(randomForest)
set.seed(1)
tf_train <-randomForest(
  logSalary~.,
  data=Hitters,
  subset=train,
  mtry = 3,
  importance=TRUE, 
  ntrees = 750)
test_pre_tf <- predict(tf_train,newdata = Hitters[-train,])
round(mean((test_pre_tf-hitters_test)^2),digits=2)
```
```{r}
set.seed(1)
tf_train <-randomForest(
  logSalary~.,
  data=Hitters,
  subset=train,
  mtry = 6,
  importance=TRUE, 
  ntrees = 750)
test_pre_tf <- predict(tf_train,newdata = Hitters[-train,])
round(mean((test_pre_tf-hitters_test)^2),digits=2)
```
```{r}
set.seed(1)
tf_train <-randomForest(
  logSalary~.,
  data=Hitters,
  subset=train,
  mtry = 19,
  importance=TRUE, 
  ntrees = 750)
test_pre_tf <- predict(tf_train,newdata = Hitters[-train,])
round(mean((test_pre_tf-hitters_test)^2),digits=2)
```
the three MSE are 0.24,0.23 and 0.21 respectively with the best MSE value of 0.21.
\newpage
4.4 Apply Boosting to the training set and then predict logSalary for the test set. Use three different values for tree depth (a.k.a. interaction depth). Report all three results (MSE), stating which result is the best.


```{r}
library(gbm)
set.seed(1)
train_h1<-slice(Hitters,train)
boost_train <- gbm(
  logSalary~.,
  data = train_h1,
  distribution = "gaussian",
  n.trees = 5000,
  interaction.depth = 4,
  shrinkage=0.1
  )
test_pre_boost <- predict(boost_train,newdata = Hitters[-train,])
round(mean((test_pre_boost-hitters_test)^2),digits=2)
```
```{r}
library(gbm)
set.seed(1)
train_h1<-slice(Hitters,train)
boost_train <- gbm(
  logSalary~.,
  data = train_h1,
  distribution = "gaussian",
  n.trees = 5000,
  interaction.depth = 10,
  shrinkage=0.1
  )
test_pre_boost <- predict(boost_train,newdata = Hitters[-train,])
round(mean((test_pre_boost-hitters_test)^2),digits=2)
```
```{r}
library(gbm)
set.seed(1)
train_h1<-slice(Hitters,train)
boost_train <- gbm(
  logSalary~.,
  data = train_h1,
  distribution = "gaussian",
  n.trees = 5000,
  interaction.depth = 1,
  shrinkage=0.1
  )
test_pre_boost <- predict(boost_train,newdata = Hitters[-train,])
round(mean((test_pre_boost-hitters_test)^2),digits=2)
```
the three MSE are 0.39,0.36 and 0.37 respectively with the best MSE value of 0.36.

\newpage

4.5 For the best Random Forest (i.e. for the best value of $m$) produce a Variable Importance Plot. Two graphs will be produced. With reference to the graph with \%IncMSE on the x-axis, write a paragraph explaining what the graph means, and summarizing the results with respect to the dataset under study.
```{r}
set.seed(1)
tf_train <-randomForest(
  logSalary~.,
  data=Hitters,
  subset=train,
  mtry = 3,
  importance=TRUE, 
  ntrees = 750)
varImpPlot(tf_train)
```

the %Inc MSE variable importance plot illustrates how variables that are most important in predicting the dependent variable are located in the most top righ of the graph so in this case, CAtBat is the most important variable. The %Inc MSE(Mean decrease accuracy) shows how much our model accuracy decreases if we leave out that variable.Higher the value of mean decrease accuracy or mean decrease gini score ,higher the importance of the variable in the model. 
\newpage
## Reference
BotBark. (2020, November 08). Top 6 advantages and disadvantages of decision tree algorithm. Retrieved March 09, 2021, from https://botbark.com/2019/12/19/top-6-advantages-and-disadvantages-of-decision-tree-algorithm/

Kumar, N. (n.d.). Advantages and disadvantages of knn algorithm in machine learning. Retrieved March 09, 2021, from http://theprofessionalspoint.blogspot.com/2019/02/advantages-and-disadvantages-of-knn.html

\newpage
## Helper's name

Lan Wang

You can write only one name.
